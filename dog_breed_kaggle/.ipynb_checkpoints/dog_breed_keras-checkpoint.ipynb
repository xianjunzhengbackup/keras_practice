{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Flatten\n",
    "from keras.layers import Conv2D,MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=f'./data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels.csv  sample_submission.csv  test  train\r\n"
     ]
    }
   ],
   "source": [
    "!ls {path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "another way to get len <br>\n",
    "len_train=!ls {path}/train | wc -l    <br>\n",
    "\n",
    "len_train=int(str(len_train[0]))      <br>\n",
    "\n",
    "len_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_train=len(os.listdir(f'{path}/train'))\n",
    "len_test=len(os.listdir(f'{path}/test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=pd.read_csv(f'{path}/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000bec180eb18c7604dcecc8fe0dba07</td>\n",
       "      <td>boston_bull</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001513dfcb2ffafc82cccf4d8bbaba97</td>\n",
       "      <td>dingo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001cdf01b096e06d78e9e5112d419397</td>\n",
       "      <td>pekinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00214f311d5d2247d5dfe4fe24b2303d</td>\n",
       "      <td>bluetick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0021f9ceb3235effd7fcde7f7538ed62</td>\n",
       "      <td>golden_retriever</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id             breed\n",
       "0  000bec180eb18c7604dcecc8fe0dba07       boston_bull\n",
       "1  001513dfcb2ffafc82cccf4d8bbaba97             dingo\n",
       "2  001cdf01b096e06d78e9e5112d419397          pekinese\n",
       "3  00214f311d5d2247d5dfe4fe24b2303d          bluetick\n",
       "4  0021f9ceb3235effd7fcde7f7538ed62  golden_retriever"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Init signature: set(self, /, *args, **kwargs)  <br>\n",
    "Docstring:     <br>\n",
    "set() -> new empty set object <br>\n",
    "set(iterable) -> new set object <br>\n",
    "\n",
    "Build an unordered collection of unique elements. <br>\n",
    "将重复项消掉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=list(set(labels['breed']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_class=len(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "底下的这种写法实在简洁"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_num=dict(zip(classes,range(n_class)))\n",
    "num_to_class=dict(zip(range(n_class),classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'affenpinscher': 115,\n",
       " 'afghan_hound': 4,\n",
       " 'african_hunting_dog': 3,\n",
       " 'airedale': 18,\n",
       " 'american_staffordshire_terrier': 52,\n",
       " 'appenzeller': 119,\n",
       " 'australian_terrier': 113,\n",
       " 'basenji': 54,\n",
       " 'basset': 6,\n",
       " 'beagle': 108,\n",
       " 'bedlington_terrier': 70,\n",
       " 'bernese_mountain_dog': 110,\n",
       " 'black-and-tan_coonhound': 103,\n",
       " 'blenheim_spaniel': 49,\n",
       " 'bloodhound': 28,\n",
       " 'bluetick': 88,\n",
       " 'border_collie': 95,\n",
       " 'border_terrier': 87,\n",
       " 'borzoi': 8,\n",
       " 'boston_bull': 56,\n",
       " 'bouvier_des_flandres': 97,\n",
       " 'boxer': 74,\n",
       " 'brabancon_griffon': 40,\n",
       " 'briard': 36,\n",
       " 'brittany_spaniel': 117,\n",
       " 'bull_mastiff': 10,\n",
       " 'cairn': 19,\n",
       " 'cardigan': 27,\n",
       " 'chesapeake_bay_retriever': 81,\n",
       " 'chihuahua': 57,\n",
       " 'chow': 69,\n",
       " 'clumber': 71,\n",
       " 'cocker_spaniel': 116,\n",
       " 'collie': 67,\n",
       " 'curly-coated_retriever': 83,\n",
       " 'dandie_dinmont': 13,\n",
       " 'dhole': 23,\n",
       " 'dingo': 53,\n",
       " 'doberman': 100,\n",
       " 'english_foxhound': 51,\n",
       " 'english_setter': 72,\n",
       " 'english_springer': 118,\n",
       " 'entlebucher': 11,\n",
       " 'eskimo_dog': 98,\n",
       " 'flat-coated_retriever': 29,\n",
       " 'french_bulldog': 63,\n",
       " 'german_shepherd': 12,\n",
       " 'german_short-haired_pointer': 41,\n",
       " 'giant_schnauzer': 68,\n",
       " 'golden_retriever': 26,\n",
       " 'gordon_setter': 77,\n",
       " 'great_dane': 90,\n",
       " 'great_pyrenees': 91,\n",
       " 'greater_swiss_mountain_dog': 34,\n",
       " 'groenendael': 65,\n",
       " 'ibizan_hound': 38,\n",
       " 'irish_setter': 94,\n",
       " 'irish_terrier': 78,\n",
       " 'irish_water_spaniel': 93,\n",
       " 'irish_wolfhound': 99,\n",
       " 'italian_greyhound': 39,\n",
       " 'japanese_spaniel': 16,\n",
       " 'keeshond': 5,\n",
       " 'kelpie': 80,\n",
       " 'kerry_blue_terrier': 46,\n",
       " 'komondor': 2,\n",
       " 'kuvasz': 0,\n",
       " 'labrador_retriever': 7,\n",
       " 'lakeland_terrier': 73,\n",
       " 'leonberg': 48,\n",
       " 'lhasa': 85,\n",
       " 'malamute': 58,\n",
       " 'malinois': 1,\n",
       " 'maltese_dog': 84,\n",
       " 'mexican_hairless': 101,\n",
       " 'miniature_pinscher': 17,\n",
       " 'miniature_poodle': 35,\n",
       " 'miniature_schnauzer': 21,\n",
       " 'newfoundland': 43,\n",
       " 'norfolk_terrier': 111,\n",
       " 'norwegian_elkhound': 15,\n",
       " 'norwich_terrier': 24,\n",
       " 'old_english_sheepdog': 107,\n",
       " 'otterhound': 33,\n",
       " 'papillon': 30,\n",
       " 'pekinese': 32,\n",
       " 'pembroke': 104,\n",
       " 'pomeranian': 96,\n",
       " 'pug': 76,\n",
       " 'redbone': 79,\n",
       " 'rhodesian_ridgeback': 92,\n",
       " 'rottweiler': 25,\n",
       " 'saint_bernard': 89,\n",
       " 'saluki': 45,\n",
       " 'samoyed': 60,\n",
       " 'schipperke': 105,\n",
       " 'scotch_terrier': 75,\n",
       " 'scottish_deerhound': 14,\n",
       " 'sealyham_terrier': 47,\n",
       " 'shetland_sheepdog': 37,\n",
       " 'shih-tzu': 112,\n",
       " 'siberian_husky': 59,\n",
       " 'silky_terrier': 55,\n",
       " 'soft-coated_wheaten_terrier': 62,\n",
       " 'staffordshire_bullterrier': 114,\n",
       " 'standard_poodle': 109,\n",
       " 'standard_schnauzer': 82,\n",
       " 'sussex_spaniel': 106,\n",
       " 'tibetan_mastiff': 22,\n",
       " 'tibetan_terrier': 9,\n",
       " 'toy_poodle': 20,\n",
       " 'toy_terrier': 86,\n",
       " 'vizsla': 102,\n",
       " 'walker_hound': 42,\n",
       " 'weimaraner': 50,\n",
       " 'welsh_springer_spaniel': 44,\n",
       " 'west_highland_white_terrier': 31,\n",
       " 'whippet': 61,\n",
       " 'wire-haired_fox_terrier': 64,\n",
       " 'yorkshire_terrier': 66}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_to_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'kuvasz',\n",
       " 1: 'malinois',\n",
       " 2: 'komondor',\n",
       " 3: 'african_hunting_dog',\n",
       " 4: 'afghan_hound',\n",
       " 5: 'keeshond',\n",
       " 6: 'basset',\n",
       " 7: 'labrador_retriever',\n",
       " 8: 'borzoi',\n",
       " 9: 'tibetan_terrier',\n",
       " 10: 'bull_mastiff',\n",
       " 11: 'entlebucher',\n",
       " 12: 'german_shepherd',\n",
       " 13: 'dandie_dinmont',\n",
       " 14: 'scottish_deerhound',\n",
       " 15: 'norwegian_elkhound',\n",
       " 16: 'japanese_spaniel',\n",
       " 17: 'miniature_pinscher',\n",
       " 18: 'airedale',\n",
       " 19: 'cairn',\n",
       " 20: 'toy_poodle',\n",
       " 21: 'miniature_schnauzer',\n",
       " 22: 'tibetan_mastiff',\n",
       " 23: 'dhole',\n",
       " 24: 'norwich_terrier',\n",
       " 25: 'rottweiler',\n",
       " 26: 'golden_retriever',\n",
       " 27: 'cardigan',\n",
       " 28: 'bloodhound',\n",
       " 29: 'flat-coated_retriever',\n",
       " 30: 'papillon',\n",
       " 31: 'west_highland_white_terrier',\n",
       " 32: 'pekinese',\n",
       " 33: 'otterhound',\n",
       " 34: 'greater_swiss_mountain_dog',\n",
       " 35: 'miniature_poodle',\n",
       " 36: 'briard',\n",
       " 37: 'shetland_sheepdog',\n",
       " 38: 'ibizan_hound',\n",
       " 39: 'italian_greyhound',\n",
       " 40: 'brabancon_griffon',\n",
       " 41: 'german_short-haired_pointer',\n",
       " 42: 'walker_hound',\n",
       " 43: 'newfoundland',\n",
       " 44: 'welsh_springer_spaniel',\n",
       " 45: 'saluki',\n",
       " 46: 'kerry_blue_terrier',\n",
       " 47: 'sealyham_terrier',\n",
       " 48: 'leonberg',\n",
       " 49: 'blenheim_spaniel',\n",
       " 50: 'weimaraner',\n",
       " 51: 'english_foxhound',\n",
       " 52: 'american_staffordshire_terrier',\n",
       " 53: 'dingo',\n",
       " 54: 'basenji',\n",
       " 55: 'silky_terrier',\n",
       " 56: 'boston_bull',\n",
       " 57: 'chihuahua',\n",
       " 58: 'malamute',\n",
       " 59: 'siberian_husky',\n",
       " 60: 'samoyed',\n",
       " 61: 'whippet',\n",
       " 62: 'soft-coated_wheaten_terrier',\n",
       " 63: 'french_bulldog',\n",
       " 64: 'wire-haired_fox_terrier',\n",
       " 65: 'groenendael',\n",
       " 66: 'yorkshire_terrier',\n",
       " 67: 'collie',\n",
       " 68: 'giant_schnauzer',\n",
       " 69: 'chow',\n",
       " 70: 'bedlington_terrier',\n",
       " 71: 'clumber',\n",
       " 72: 'english_setter',\n",
       " 73: 'lakeland_terrier',\n",
       " 74: 'boxer',\n",
       " 75: 'scotch_terrier',\n",
       " 76: 'pug',\n",
       " 77: 'gordon_setter',\n",
       " 78: 'irish_terrier',\n",
       " 79: 'redbone',\n",
       " 80: 'kelpie',\n",
       " 81: 'chesapeake_bay_retriever',\n",
       " 82: 'standard_schnauzer',\n",
       " 83: 'curly-coated_retriever',\n",
       " 84: 'maltese_dog',\n",
       " 85: 'lhasa',\n",
       " 86: 'toy_terrier',\n",
       " 87: 'border_terrier',\n",
       " 88: 'bluetick',\n",
       " 89: 'saint_bernard',\n",
       " 90: 'great_dane',\n",
       " 91: 'great_pyrenees',\n",
       " 92: 'rhodesian_ridgeback',\n",
       " 93: 'irish_water_spaniel',\n",
       " 94: 'irish_setter',\n",
       " 95: 'border_collie',\n",
       " 96: 'pomeranian',\n",
       " 97: 'bouvier_des_flandres',\n",
       " 98: 'eskimo_dog',\n",
       " 99: 'irish_wolfhound',\n",
       " 100: 'doberman',\n",
       " 101: 'mexican_hairless',\n",
       " 102: 'vizsla',\n",
       " 103: 'black-and-tan_coonhound',\n",
       " 104: 'pembroke',\n",
       " 105: 'schipperke',\n",
       " 106: 'sussex_spaniel',\n",
       " 107: 'old_english_sheepdog',\n",
       " 108: 'beagle',\n",
       " 109: 'standard_poodle',\n",
       " 110: 'bernese_mountain_dog',\n",
       " 111: 'norfolk_terrier',\n",
       " 112: 'shih-tzu',\n",
       " 113: 'australian_terrier',\n",
       " 114: 'staffordshire_bullterrier',\n",
       " 115: 'affenpinscher',\n",
       " 116: 'cocker_spaniel',\n",
       " 117: 'brittany_spaniel',\n",
       " 118: 'english_springer',\n",
       " 119: 'appenzeller'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_to_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最好是将X_train,Y_train都做成是DataFrame，这样可以直接调用to_csv<br>\n",
    "但是对于图形识别的project，这是没用的。因为CV第一步都是卷积，对3层进行卷积，而DataFrame是二维的，无法卷积。除非输入图形只有一层。<br>\n",
    "底下的操作就是如何将输入处理成DataFrame<br>\n",
    "width=300\n",
    "X_train=pd.DataFrame(np.zeros((len_train,width*width*3)),index=range(len_train))\n",
    "Y_train=pd.DataFrame(np.zeros((len_train,n_class)),columns=list(class_to_num.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "width=300\n",
    "X_train=np.zeros((len_train,width,width,3))\n",
    "Y_train=np.zeros((len_train,n_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(X_train[1])\n",
    "\n",
    "print(num_to_class[70])\n",
    "\n",
    "print(os.listdir(f'{path}/train')[1])\n",
    "\n",
    "labels.loc[labels['id']==os.listdir(f'{path}/test')[1][:-4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10222/10222 [00:53<00:00, 191.74it/s]\n"
     ]
    }
   ],
   "source": [
    "fp_list=os.listdir(f'{path}/train')\n",
    "n=len(fp_list)\n",
    "for i in tqdm(range(n)):\n",
    "    fp=fp_list[i]\n",
    "    X_train[i]=cv2.resize(cv2.imread(f'{path}/train/{fp}'),dsize = (width, width))\n",
    "    file_name=fp[:-4]\n",
    "    breed_name=labels.loc[labels['id']==file_name]['breed']\n",
    "    breed_name=breed_name.get_values()[0]\n",
    "    Y_train[i][class_to_num[breed_name]]=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fp_list=os.listdir(f'{path}/train')\n",
    "n=len(fp_list)\n",
    "for i in tqdm(range(n)):\n",
    "#for fp in os.listdir(f'{path}/train'):\n",
    "    fp=fp_list[i]\n",
    "    X_train.iloc[i,:]=cv2.resize(cv2.imread(f'{path}/train/{fp}'),dsize = (width, width)).flatten()\n",
    "    file_name=fp[:-4]\n",
    "    breed_name=labels.loc[labels['id']==file_name]['breed']\n",
    "    breed_name=breed_name.get_values()[0]\n",
    "    Y_train.iloc[i,class_to_num[breed_name]]=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_train.to_csv(\"X_train_23_05.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y_train.to_csv(\"Y_train_23_05.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 300, 300, 3)       0         \n",
      "_________________________________________________________________\n",
      "resnet50 (Model)             (None, 1, 1, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 2048)              0         \n",
      "=================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n",
      " 9728/10222 [===========================>..] - ETA: 4s"
     ]
    }
   ],
   "source": [
    "#this code from kaggle which runs very fast\n",
    "from keras.applications import resnet50\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "#from keras.preprocessing import image\n",
    "#from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "resnet_model = resnet50.ResNet50(include_top = False, weights='imagenet', input_shape = (300, 300, 3))\n",
    "    \n",
    "inputs = Input((width, width, 3))\n",
    "x = inputs\n",
    "x = resnet_model(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "resnet_model = Model(inputs, x)\n",
    "resnet_model.summary()\n",
    "\n",
    "features = resnet_model.predict(X_train, batch_size=64, verbose=1)\n",
    "\n",
    "\n",
    "inputs = Input(features.shape[1:])\n",
    "x = inputs\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(n_class, activation='softmax')(x)\n",
    "model = Model(inputs, x)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "h = model.fit(features, y_train, batch_size=128, epochs=50, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Train on 9199 samples, validate on 1023 samples\n",
      "Epoch 1/50\n",
      "9199/9199 [==============================] - 84s 9ms/step - loss: 5.9448 - acc: 0.0074 - val_loss: 5.1759 - val_acc: 0.0088\n",
      "Epoch 2/50\n",
      "9199/9199 [==============================] - 76s 8ms/step - loss: 5.1038 - acc: 0.0080 - val_loss: 5.0475 - val_acc: 0.0088\n",
      "Epoch 3/50\n",
      "9199/9199 [==============================] - 74s 8ms/step - loss: 5.0146 - acc: 0.0075 - val_loss: 5.0113 - val_acc: 0.0039\n",
      "Epoch 4/50\n",
      "9199/9199 [==============================] - 74s 8ms/step - loss: 4.9989 - acc: 0.0090 - val_loss: 5.0031 - val_acc: 0.0049\n",
      "Epoch 5/50\n",
      "9199/9199 [==============================] - 74s 8ms/step - loss: 4.9883 - acc: 0.0093 - val_loss: 4.9922 - val_acc: 0.0039\n",
      "Epoch 6/50\n",
      "9199/9199 [==============================] - 74s 8ms/step - loss: 4.9814 - acc: 0.0072 - val_loss: 5.0013 - val_acc: 0.0049\n",
      "Epoch 7/50\n",
      "9199/9199 [==============================] - 74s 8ms/step - loss: 4.9845 - acc: 0.0072 - val_loss: 4.9983 - val_acc: 0.0039\n",
      "Epoch 8/50\n",
      "9199/9199 [==============================] - 74s 8ms/step - loss: 4.9869 - acc: 0.0076 - val_loss: 5.0113 - val_acc: 0.0088\n",
      "Epoch 9/50\n",
      "9199/9199 [==============================] - 74s 8ms/step - loss: 4.9808 - acc: 0.0084 - val_loss: 4.9991 - val_acc: 0.0088\n",
      "Epoch 10/50\n",
      "9199/9199 [==============================] - 74s 8ms/step - loss: 4.9744 - acc: 0.0067 - val_loss: 4.9935 - val_acc: 0.0088\n",
      "Epoch 11/50\n",
      "9199/9199 [==============================] - 74s 8ms/step - loss: 4.9647 - acc: 0.0087 - val_loss: 4.9869 - val_acc: 0.0088\n",
      "Epoch 12/50\n",
      "9199/9199 [==============================] - 74s 8ms/step - loss: 4.9636 - acc: 0.0104 - val_loss: 4.9816 - val_acc: 0.0098\n",
      "Epoch 13/50\n",
      "9199/9199 [==============================] - 74s 8ms/step - loss: 4.9559 - acc: 0.0125 - val_loss: 4.9761 - val_acc: 0.0088\n",
      "Epoch 14/50\n",
      "9199/9199 [==============================] - 74s 8ms/step - loss: 4.9433 - acc: 0.0112 - val_loss: 4.9626 - val_acc: 0.0127\n",
      "Epoch 15/50\n",
      "9199/9199 [==============================] - 74s 8ms/step - loss: 4.8514 - acc: 0.0110 - val_loss: 4.7262 - val_acc: 0.0088\n",
      "Epoch 16/50\n",
      "1696/9199 [====>.........................] - ETA: 57s - loss: 4.7485 - acc: 0.0100"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-5248485c03c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msgd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1000\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Conv2D(32,(3,3),activation='relu',input_shape=(width,width,3)))\n",
    "model.add(Conv2D(32,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(n_class,activation='relu'))\n",
    "\n",
    "sgd=SGD(lr=0.01,decay=1e-6,momentum=0.9,nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',optimizer=sgd,metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train,Y_train,batch_size=32,epochs=50,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = model.predict(X_test, batch_size=128)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
